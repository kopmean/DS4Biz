{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kopmean/DS4Biz/blob/main/1_63070240_%E0%B8%A3%E0%B8%A1%E0%B8%B4%E0%B8%95%E0%B8%B2_63070243_%E0%B8%A8%E0%B8%B4%E0%B8%A3%E0%B8%B2_A2T1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "น.ส.รมิตา ศรีภูธร 63070240\n",
        "\n",
        "นาย ศิรา อัตตวนิช 63070243"
      ],
      "metadata": {
        "id": "Sd-tcyikhDdL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ทำการโหลดข้อมูลจาก google drive"
      ],
      "metadata": {
        "id": "r9qQexo7C-dO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHFF6GraSp-5",
        "outputId": "33c961f9-4114-4cf9-fe37-bfbf8bc5accb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KlTQknfjV_g4CM6gyzoVdNSvGYec7893\n",
            "To: /content/news.csv\n",
            "\r  0% 0.00/6.56M [00:00<?, ?B/s]\r100% 6.56M/6.56M [00:00<00:00, 215MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1KlTQknfjV_g4CM6gyzoVdNSvGYec7893"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzkEO-CqTAQk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ทำการสร้าง dataframe\n",
        "- news_title\n",
        "- news_content"
      ],
      "metadata": {
        "id": "WPAivLBmDa5N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VioqIx5S505"
      },
      "outputs": [],
      "source": [
        "news = pd.read_csv('/content/news.csv')\n",
        "# ทำการสร้าง dataframe news_title ซึ่ง category เก็บประเภทของข่าวและ title_content เก็บเนื้อหาของข่าวแต่รวมหัวข้อของข่าวด้วย\n",
        "news_title = news[['category','title_content']]\n",
        "# ทำการเปลี่ยนชื่อ column ให้ column เป็น category และ content\n",
        "news_title.columns = ['category','content']\n",
        "# ทำการสร้าง dataframe news_title ซึ่ง category เก็บประเภทของข่าวและ content เก็บแต่เนื้อหาของข่าว\n",
        "news_content = news[['category','content']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icYIFYujTE6w"
      },
      "source": [
        "## Clean Data\n",
        "- stem\n",
        "- lematize\n",
        "- stop word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs2Gg0fqS6ZQ",
        "outputId": "752dd51c-e99e-4c23-e948-563a4155d384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-24 03:37:26.465016: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 3.3 MB/s \n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install -U nltk -qq\n",
        "!pip install -U spacy -qq\n",
        "!python -m spacy download en -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JfIh3c8THXa",
        "outputId": "a595cffb-ea05-40da-9fdc-e1b17bb5a57b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: \n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from collections import Counter\n",
        "spacyNlp = spacy.load('en_core_web_sm')\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('tagsets')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import warnings\n",
        "warnings.warn('')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "สร้าง function clean_data เป็น function ในการคลีนข้อมูลเป็นการทำ text Pre-Processing ด้วยการทำ\n",
        "- stem แบบ porter\n",
        "- lemmatization\n",
        "- removing stop words\n",
        "\n",
        "เป็น function ที่รับค่า dataframe และ return ออกมาเป็น dataframe"
      ],
      "metadata": {
        "id": "vSFN87xkGMg1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6LXepXUHqQG"
      },
      "outputs": [],
      "source": [
        "def clean_data(data):\n",
        "  # ทำ stem\n",
        "  porter = PorterStemmer()\n",
        "  # รับค่า string ของแต่ละ row และได้ผลลัพธ์เป็น list ของ token\n",
        "  data.loc[:, 'content'] = data['content'].apply(lambda text : [porter.stem(wd) for wd in nltk.word_tokenize(text)])\n",
        "\n",
        "  # ทำ lemmatization\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  def lemmatiz(lis):\n",
        "    li = []\n",
        "    for i in lis:\n",
        "      li.append(lemmatizer.lemmatize(i))\n",
        "    return li\n",
        "  # รับค่า list token ของแต่ละ row และได้ผลลัพธ์เป็น list\n",
        "  data.loc[:, 'content'] = data['content'].apply(lambda text : lemmatiz(text))\n",
        "\n",
        "  # ทำ stop word\n",
        "  a = set(stopwords.words('english'))\n",
        "  # เป็นการทำโดยเช็คแต่ละ index ใน list ซึ่งถ้าเป็นคำใน stop word จะไม่อยู่ใน list\n",
        "  data.loc[:, 'content'] = data['content'].apply(lambda text : [x for x in text if x not in a])\n",
        "  # หลังจากเอา stop word ออกเราจะทำการนำ list ของ token มาต่อกันเป็น string\n",
        "  data.loc[:, 'content'] = data['content'].apply(lambda lis: \" \".join(lis))\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3eABhX8d5St",
        "outputId": "a1d60f08-864d-4803-ab57-fb8511963862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1951: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[selected_item_labels] = value\n"
          ]
        }
      ],
      "source": [
        "# สร้าง dataframe df_clean โดยนำ dataframe news_title เข้า function clean_data\n",
        "df_clean = clean_data(news_title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "U7XJFKxOkZOU",
        "outputId": "c2a2eb3e-291a-4184-b98b-78fcc7cdb226"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        category                                            content\n",
              "0     technology  21st-centuri sport : digit technolog chang fac...\n",
              "1       business  asian quak hit european share asian quak hit e...\n",
              "2     technology  bt offer free net phone call bt offer custom f...\n",
              "3       business  barclay share merger talk barclay share merger...\n",
              "4          sport  barkley fit match ireland england centr olli b...\n",
              "...          ...                                                ...\n",
              "1403       sport  woodward eye brennan lion woodward eye brennan...\n",
              "1404    business  worldcom trial start new york trial berni ebbe...\n",
              "1405    business  yuko accus lie court yuko accus lie courtrussi...\n",
              "1406    business  yuko drop bank court bid russian oil compani y...\n",
              "1407       sport  zambia confid cautiou zambia 's technic direct...\n",
              "\n",
              "[1408 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23e74d19-12c7-4eec-9fb6-b23d8ea696f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>technology</td>\n",
              "      <td>21st-centuri sport : digit technolog chang fac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>asian quak hit european share asian quak hit e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>technology</td>\n",
              "      <td>bt offer free net phone call bt offer custom f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>barclay share merger talk barclay share merger...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sport</td>\n",
              "      <td>barkley fit match ireland england centr olli b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1403</th>\n",
              "      <td>sport</td>\n",
              "      <td>woodward eye brennan lion woodward eye brennan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1404</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom trial start new york trial berni ebbe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1405</th>\n",
              "      <td>business</td>\n",
              "      <td>yuko accus lie court yuko accus lie courtrussi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1406</th>\n",
              "      <td>business</td>\n",
              "      <td>yuko drop bank court bid russian oil compani y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1407</th>\n",
              "      <td>sport</td>\n",
              "      <td>zambia confid cautiou zambia 's technic direct...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1408 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23e74d19-12c7-4eec-9fb6-b23d8ea696f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-23e74d19-12c7-4eec-9fb6-b23d8ea696f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-23e74d19-12c7-4eec-9fb6-b23d8ea696f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "df_clean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwRJqffiqH8Q"
      },
      "source": [
        "# Document term matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP6gjHeBnQbK"
      },
      "source": [
        "## Bag of word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxEBjXmF_qwd"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "สร้าง function Bag_of_word เป็นการเก็บคำในเอกสารทั้งหมด และจะบอกว่าแต่ละข่าวมีคำศัพท์นั้นๆ กี่คำ\n",
        "\n",
        "เป็น function ที่รับค่า dataframe และ return เป็นค่าของ matrix ที่มีมิติตามจำนวนข่าว และจำนวนคำศัพท์ทั้งหมดใน corpus"
      ],
      "metadata": {
        "id": "l2rrYlW0Vf6o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rJY0V7hnAW0"
      },
      "outputs": [],
      "source": [
        "def Bag_of_word(data):\n",
        "  vectorizer = CountVectorizer()\n",
        "  # สร้าง corpus เป็น list ที่เก็บค่าของแต่ละ row ใน column content\n",
        "  corpus = df_clean['content'].copy().tolist()\n",
        "  X = vectorizer.fit_transform(corpus)\n",
        "  return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFrcxtt4_0zV",
        "outputId": "3407b746-acda-4585-c2bc-089b85ebfee5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1408, 18152)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# สร้าง matrix X โดยนำ dataframe df_clean เข้า function Bag_of_word\n",
        "X = Bag_of_word(df_clean)\n",
        "# เช็คมิติของ matrix X\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRMS9cBRjwxQ"
      },
      "source": [
        "## TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TumZ4wE_tCx"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "สร้าง function TF_IDF เป็นการเก็บคำในเอกสารทั้งหมด และจะบอกว่าคำศัพท์แต่ละคำในข่าวมีค่านำ้หนักความสำคัญใน corpus เป็นเท่าใด\n",
        "\n",
        "เป็น function ที่รับค่า dataframe และ return เป็นค่าของเวกเตอร์ที่มีมิติตามจำนวนข่าว และจำนวนคำศัพท์ทั้งหมดใน corpus"
      ],
      "metadata": {
        "id": "6DItoeUgaNi8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NBb--k3koHc"
      },
      "outputs": [],
      "source": [
        "def TF_IDF(data):\n",
        "  # สร้าง corpus เป็น list ที่เก็บค่าของแต่ละ row ใน column content\n",
        "  corpus = data.copy().content.to_list()\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  X = vectorizer.fit_transform(corpus)\n",
        "  vectorizer.get_feature_names_out()\n",
        "  return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3FntBTmmtpb",
        "outputId": "16189650-3fe1-4e28-bbd7-db524c60e92e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1408, 18152)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# สร้าง matrix X โดยนำ dataframe df_clean เข้า function TF_IDF\n",
        "X = TF_IDF(df_clean)\n",
        "# เช็คมิติของ matrix X\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OImjiMd7oAzk"
      },
      "source": [
        "# Modeling\n",
        "- KNN\n",
        "- Naive Bayes\n",
        "- Xgboost\n",
        "- SVC\n",
        "- LogisticRegression\n",
        "- Random frorest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcf7IBVtr_pG"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "สร้าง function model โดยรับค่า X (array ของ Document term matrix) และ y (array ที่เก็บค่า category)"
      ],
      "metadata": {
        "id": "QN47Pi3DgJHV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20hNPOfOp0Ce"
      },
      "outputs": [],
      "source": [
        "def model(X, y):\n",
        "  # Split Data 80:20\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=63070243)\n",
        "\n",
        "  # KNN modeling\n",
        "  # ใช้ n = 3\n",
        "  neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "  neigh.fit(X_train, y_train)\n",
        "  predicted = neigh.predict(X_test)\n",
        "  print('KNN model')\n",
        "  print(classification_report(y_test, predicted))\n",
        "  print('Mean 5-fold cross validation: {}'.format(cross_val_score(neigh, X, y, cv = 5).mean()))\n",
        "  print('--------------------------------------------------------')\n",
        "\n",
        "  # Naive Bayes\n",
        "  gnb = GaussianNB()\n",
        "  predicted = gnb.fit(X_train, y_train).predict(X_test)\n",
        "  print('Naive Bayes model')\n",
        "  print(classification_report(y_test, predicted))\n",
        "  print('Mean 5-fold cross validation: {}'.format(cross_val_score(gnb, X, y, cv = 5).mean()))\n",
        "  print('--------------------------------------------------------')\n",
        "\n",
        "  # Xgboost\n",
        "  clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
        "    max_depth=1, random_state=0).fit(X_train, y_train)\n",
        "  predicted = clf.predict(X_test)\n",
        "  print('Xgboost')\n",
        "  print(classification_report(y_test, predicted))\n",
        "  print('Mean 5-fold cross validation: {}'.format(cross_val_score(clf, X, y, cv = 5).mean()))\n",
        "  print('--------------------------------------------------------')\n",
        "\n",
        "  # SVC\n",
        "  clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "  clf.fit(X_train, y_train)\n",
        "  predicted = clf.predict(X_test)\n",
        "  print('SVC')\n",
        "  print(classification_report(y_test, predicted))\n",
        "  print('Mean 5-fold cross validation: {}'.format(cross_val_score(clf, X, y, cv = 5).mean()))\n",
        "  print('--------------------------------------------------------')\n",
        "\n",
        "  # LogisticRegerssion\n",
        "  clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
        "  predicted = clf.predict(X_test)\n",
        "  print('LogisticRegerssion')\n",
        "  print(classification_report(y_test, predicted))\n",
        "  print('Mean 5-fold cross validation: {}'.format(cross_val_score(clf, X, y, cv = 5).mean()))\n",
        "  print('--------------------------------------------------------')\n",
        "\n",
        "  # Random forest\n",
        "  clf = RandomForestClassifier(max_depth=9000, random_state=0)\n",
        "  clf.fit(X_train, y_train)\n",
        "  predicted = clf.predict(X_test)\n",
        "  print('Random forest')\n",
        "  print(classification_report(y_test, predicted))\n",
        "  print('Mean 5-fold cross validation: {}'.format(cross_val_score(clf, X, y, cv = 5).mean()))\n",
        "  print('--------------------------------------------------------')\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMerY4aODD46"
      },
      "source": [
        "# Merge function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWMYp9cUMZnt"
      },
      "source": [
        "## Experiment 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_6VT7_VX1jz"
      },
      "outputs": [],
      "source": [
        "news = pd.read_csv('/content/news.csv')\n",
        "news_title = news[['category','title_content']]\n",
        "news_title.columns = ['category','content']\n",
        "news_content = news[['category','content']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Prg3DfO7OQS1"
      },
      "source": [
        "สร้างฟังก์ชันที่รวม preprocess, tf_idf, modeling เข้าด้วยกัน เป็น pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWsKvXuPDccQ"
      },
      "outputs": [],
      "source": [
        "def tf_idf_model(data):\n",
        "  df = data.copy()\n",
        "  # ทำ text Pre-Processing ด้วยการทำ stem แบบ porter, lemmatization และ removing stop words\n",
        "  # ผ่าน function clean_data ซึ่งรับค่าเป็น dataframe และ return เป็น dataframe\n",
        "  df = clean_data(df)\n",
        "\n",
        "  # ทำ TF-IDF เก็บคำในเอกสารทั้งหมด และจะบอกว่าคำศัพท์แต่ละคำในข่าวมีค่านำ้หนักความสำคัญใน corpus เป็นเท่าใด\n",
        "  # ผ่าน function TF_IDF ซึ่งรับค่าเป็น dataframe และ return เป็น matrix\n",
        "  X = TF_IDF(df)\n",
        "  X = X.toarray()\n",
        "  # สร้าง NumPy array โดยใช้ข้อมูลจาก column category ของ dataframe df\n",
        "  y = df['category'].to_numpy()\n",
        "\n",
        "  model(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH4hRbE5NfwM"
      },
      "source": [
        "news_content (news) ทำ TF-IDF รวมกับทุก Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfMTqPHGNp11",
        "outputId": "0cb164fd-05bc-4b7d-f2a4-1b74af7dc860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.97      0.91      0.94       110\n",
            "       sport       0.97      0.98      0.98       102\n",
            "  technology       0.91      0.99      0.95        70\n",
            "\n",
            "    accuracy                           0.95       282\n",
            "   macro avg       0.95      0.96      0.95       282\n",
            "weighted avg       0.96      0.95      0.95       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.9531258675954671\n",
            "--------------------------------------------------------\n",
            "Naive Bayes model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.98      0.85      0.91       110\n",
            "       sport       0.92      1.00      0.96       102\n",
            "  technology       0.88      0.94      0.91        70\n",
            "\n",
            "    accuracy                           0.93       282\n",
            "   macro avg       0.93      0.93      0.93       282\n",
            "weighted avg       0.93      0.93      0.93       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.9374977915751748\n",
            "--------------------------------------------------------\n",
            "Xgboost\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.99      0.98      0.99       110\n",
            "       sport       0.99      1.00      1.00       102\n",
            "  technology       0.99      0.99      0.99        70\n",
            "\n",
            "    accuracy                           0.99       282\n",
            "   macro avg       0.99      0.99      0.99       282\n",
            "weighted avg       0.99      0.99      0.99       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.9573811867444032\n",
            "--------------------------------------------------------\n",
            "SVC\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.98      0.86      0.92       110\n",
            "       sport       0.97      0.89      0.93       102\n",
            "  technology       0.74      0.96      0.83        70\n",
            "\n",
            "    accuracy                           0.90       282\n",
            "   macro avg       0.89      0.90      0.89       282\n",
            "weighted avg       0.91      0.90      0.90       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.9190277882940865\n",
            "--------------------------------------------------------\n",
            "LogisticRegerssion\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.99      0.97      0.98       110\n",
            "       sport       0.99      0.99      0.99       102\n",
            "  technology       0.96      0.99      0.97        70\n",
            "\n",
            "    accuracy                           0.98       282\n",
            "   macro avg       0.98      0.98      0.98       282\n",
            "weighted avg       0.98      0.98      0.98       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.9801065091744275\n",
            "--------------------------------------------------------\n",
            "Random forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.99      0.98      0.99       110\n",
            "       sport       0.99      0.99      0.99       102\n",
            "  technology       0.99      1.00      0.99        70\n",
            "\n",
            "    accuracy                           0.99       282\n",
            "   macro avg       0.99      0.99      0.99       282\n",
            "weighted avg       0.99      0.99      0.99       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.9701622876757275\n",
            "--------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "tf_idf_model(news_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXoSLZrMMv68"
      },
      "source": [
        "news_title (news + title) ทำ TF-IDF รวมกับทุก Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so1rwviGMuRe",
        "outputId": "41b4716e-274d-49d3-e8e8-1465e7f93cbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.97      0.91      0.94       110\n",
            "       sport       0.97      0.98      0.98       102\n",
            "  technology       0.91      0.99      0.95        70\n",
            "\n",
            "    accuracy                           0.95       282\n",
            "   macro avg       0.95      0.96      0.95       282\n",
            "weighted avg       0.96      0.95      0.95       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.9559677948562632\n",
            "--------------------------------------------------------\n",
            "Naive Bayes model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.97      0.86      0.91       110\n",
            "       sport       0.93      0.99      0.96       102\n",
            "  technology       0.88      0.94      0.91        70\n",
            "\n",
            "    accuracy                           0.93       282\n",
            "   macro avg       0.93      0.93      0.93       282\n",
            "weighted avg       0.93      0.93      0.93       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.9346583882284648\n",
            "--------------------------------------------------------\n",
            "Xgboost\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.99      0.94      0.96       110\n",
            "       sport       0.97      1.00      0.99       102\n",
            "  technology       0.95      0.99      0.97        70\n",
            "\n",
            "    accuracy                           0.97       282\n",
            "   macro avg       0.97      0.97      0.97       282\n",
            "weighted avg       0.97      0.97      0.97       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.9651927008404634\n",
            "--------------------------------------------------------\n",
            "SVC\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.98      0.85      0.91       110\n",
            "       sport       0.97      0.88      0.92       102\n",
            "  technology       0.71      0.96      0.82        70\n",
            "\n",
            "    accuracy                           0.89       282\n",
            "   macro avg       0.89      0.89      0.88       282\n",
            "weighted avg       0.91      0.89      0.89       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.9069584311350042\n",
            "--------------------------------------------------------\n",
            "LogisticRegerssion\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.99      0.97      0.98       110\n",
            "       sport       0.99      0.99      0.99       102\n",
            "  technology       0.96      0.99      0.97        70\n",
            "\n",
            "    accuracy                           0.98       282\n",
            "   macro avg       0.98      0.98      0.98       282\n",
            "weighted avg       0.98      0.98      0.98       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.9829509603493097\n",
            "--------------------------------------------------------\n",
            "Random forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.99      0.99      0.99       110\n",
            "       sport       0.98      0.99      0.99       102\n",
            "  technology       1.00      0.99      0.99        70\n",
            "\n",
            "    accuracy                           0.99       282\n",
            "   macro avg       0.99      0.99      0.99       282\n",
            "weighted avg       0.99      0.99      0.99       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.9694480199893997\n",
            "--------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "tf_idf_model(news_title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuOUFtVaMnxK"
      },
      "source": [
        "## Experiment 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyGgabHZO3sT"
      },
      "source": [
        "สร้างฟังก์ชันที่รวม preprocess, bag of word, modeling เข้าด้วยกัน เป็น pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tnO-7LvL1Ph"
      },
      "outputs": [],
      "source": [
        "def bag_of_word_model(data):\n",
        "  df = data.copy()\n",
        "  # ทำ text Pre-Processing ด้วยการทำ stem แบบ porter, lemmatization และ removing stop words\n",
        "  # ผ่าน function clean_data ซึ่งรับค่าเป็น dataframe และ return เป็น dataframe\n",
        "  df = clean_data(df)\n",
        "  # ทำ baf of word เก็บคำในเอกสารทั้งหมด และจะบอกว่าแต่ละข่าวมีคำศัพท์นั้นๆ กี่คำ\n",
        "  # ผ่าน function Bag_of_word ซึ่งรับค่าเป็น dataframe และ return เป็น matrix\n",
        "  X = Bag_of_word(df)\n",
        "  X = X.toarray()\n",
        "  # สร้าง NumPy array โดยใช้ข้อมูลจาก column category ของ dataframe df\n",
        "  y = df['category'].to_numpy()\n",
        "\n",
        "  model(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kb_AVITOLJh"
      },
      "source": [
        "news_content (news) ทำ bag of word รวมกับทุก Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdZLw_ENE-wW",
        "outputId": "6a2b9409-c896-4eb8-ce1a-95a176518303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.90      0.68      0.78       110\n",
            "       sport       0.64      0.99      0.78       102\n",
            "  technology       0.98      0.59      0.73        70\n",
            "\n",
            "    accuracy                           0.77       282\n",
            "   macro avg       0.84      0.75      0.76       282\n",
            "weighted avg       0.83      0.77      0.77       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.7706165922112012\n",
            "--------------------------------------------------------\n",
            "Naive Bayes model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.96      0.86      0.91       110\n",
            "       sport       0.93      0.98      0.96       102\n",
            "  technology       0.88      0.96      0.92        70\n",
            "\n",
            "    accuracy                           0.93       282\n",
            "   macro avg       0.93      0.93      0.93       282\n",
            "weighted avg       0.93      0.93      0.93       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.9403346710077989\n",
            "--------------------------------------------------------\n",
            "Xgboost\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.97      0.95      0.96       110\n",
            "       sport       0.98      0.99      0.99       102\n",
            "  technology       0.96      0.97      0.96        70\n",
            "\n",
            "    accuracy                           0.97       282\n",
            "   macro avg       0.97      0.97      0.97       282\n",
            "weighted avg       0.97      0.97      0.97       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.9552560510840211\n",
            "--------------------------------------------------------\n",
            "SVC\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.97      0.83      0.89       110\n",
            "       sport       0.97      0.89      0.93       102\n",
            "  technology       0.71      0.96      0.82        70\n",
            "\n",
            "    accuracy                           0.88       282\n",
            "   macro avg       0.88      0.89      0.88       282\n",
            "weighted avg       0.90      0.88      0.89       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.8763963554680598\n",
            "--------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegerssion\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       1.00      0.95      0.98       110\n",
            "       sport       0.99      1.00      1.00       102\n",
            "  technology       0.95      1.00      0.97        70\n",
            "\n",
            "    accuracy                           0.98       282\n",
            "   macro avg       0.98      0.98      0.98       282\n",
            "weighted avg       0.98      0.98      0.98       282\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean 5-fold cross validation: 0.9794048610585296\n",
            "--------------------------------------------------------\n",
            "Random forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       1.00      0.98      0.99       110\n",
            "       sport       0.98      1.00      0.99       102\n",
            "  technology       0.99      0.99      0.99        70\n",
            "\n",
            "    accuracy                           0.99       282\n",
            "   macro avg       0.99      0.99      0.99       282\n",
            "weighted avg       0.99      0.99      0.99       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.9694505439034854\n",
            "--------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "bag_of_word_model(news_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-mRVJhqSqMf"
      },
      "source": [
        "news_title (news + title) ทำ bag of word รวมกับทุก Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbXVsRKhSsmL",
        "outputId": "5f6b6b23-e2f8-4d0b-e992-1960e04ddb6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.90      0.68      0.78       110\n",
            "       sport       0.64      0.99      0.78       102\n",
            "  technology       0.98      0.59      0.73        70\n",
            "\n",
            "    accuracy                           0.77       282\n",
            "   macro avg       0.84      0.75      0.76       282\n",
            "weighted avg       0.83      0.77      0.77       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.7706165922112012\n",
            "--------------------------------------------------------\n",
            "Naive Bayes model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.96      0.86      0.91       110\n",
            "       sport       0.93      0.98      0.96       102\n",
            "  technology       0.88      0.96      0.92        70\n",
            "\n",
            "    accuracy                           0.93       282\n",
            "   macro avg       0.93      0.93      0.93       282\n",
            "weighted avg       0.93      0.93      0.93       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.9403346710077989\n",
            "--------------------------------------------------------\n",
            "Xgboost\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.97      0.95      0.96       110\n",
            "       sport       0.98      0.99      0.99       102\n",
            "  technology       0.96      0.97      0.96        70\n",
            "\n",
            "    accuracy                           0.97       282\n",
            "   macro avg       0.97      0.97      0.97       282\n",
            "weighted avg       0.97      0.97      0.97       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.9552560510840211\n",
            "--------------------------------------------------------\n",
            "SVC\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       0.97      0.83      0.89       110\n",
            "       sport       0.97      0.89      0.93       102\n",
            "  technology       0.71      0.96      0.82        70\n",
            "\n",
            "    accuracy                           0.88       282\n",
            "   macro avg       0.88      0.89      0.88       282\n",
            "weighted avg       0.90      0.88      0.89       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.8763963554680598\n",
            "--------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegerssion\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       1.00      0.95      0.98       110\n",
            "       sport       0.99      1.00      1.00       102\n",
            "  technology       0.95      1.00      0.97        70\n",
            "\n",
            "    accuracy                           0.98       282\n",
            "   macro avg       0.98      0.98      0.98       282\n",
            "weighted avg       0.98      0.98      0.98       282\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean 5-fold cross validation: 0.9794048610585296\n",
            "--------------------------------------------------------\n",
            "Random forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    business       1.00      0.98      0.99       110\n",
            "       sport       0.98      1.00      0.99       102\n",
            "  technology       0.99      0.99      0.99        70\n",
            "\n",
            "    accuracy                           0.99       282\n",
            "   macro avg       0.99      0.99      0.99       282\n",
            "weighted avg       0.99      0.99      0.99       282\n",
            "\n",
            "Mean 5-fold cross validation: 0.9694505439034854\n",
            "--------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "bag_of_word_model(news_title)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "จาก Experiment1 การใช้ TF-IDF ในการทำ classification ในข้อมูลเฉพาะเนื้อหาของข่าว(news_content) และหัวข้อข่าว+เนื้อหาของข่าว(news_title) เมื่อนำเข้า model(KNN, Naive Bayes, Xgboost, SVC, LogisticRegression, Random frorest)\n",
        "ทำให้เห็นว่าค่า accuracy นั้นมีค่าใกล้เคียงกันมาก\n",
        "\n",
        "แต่ Experiment2 ซึ่งใช้ Bag of word ในการทำ classification จะเห็นได้ว่าค่า accuracy ของ model นั้นเหมือนกันทั้ง news_content และ news_title"
      ],
      "metadata": {
        "id": "du_8l2ZjZmkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "TF-IDF\n",
        "                  KNN  NaiveBayes Xgboost   SVC  LogisticRegression  RamdomFrorest\n",
        "  news_content   0.953    0.937    0.957   0.919        0.980            0.970\n",
        "  news_title     0.955    0.935    0.965   0.907        0.983            0.969\n",
        "```"
      ],
      "metadata": {
        "id": "8eptfRB5YSAk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Bag of words\n",
        "                  KNN  NaiveBayes Xgboost   SVC  LogisticRegression  RamdomFrorest\n",
        "  news_content   0.771    0.940    0.955   0.876        0.979            0.969\n",
        "  news_title     0.771    0.940    0.955   0.876        0.979            0.969\n",
        "```"
      ],
      "metadata": {
        "id": "Qmo2mx9Ial0B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "จาก Experiment1 และ Experiment2 ทำให้ทราบว่า\n",
        "model logistic Regression โดยใช้ข้อมูล news_title และใช้ document term metric แบบ TF-IDF นั้นได้ accuracy สูงที่สุดคือ 0.983"
      ],
      "metadata": {
        "id": "1Za-Aci9btH_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XSXJI6rVaiPi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}